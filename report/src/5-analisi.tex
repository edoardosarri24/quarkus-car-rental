\chapter{Analisi E2E}
In questo capitolo andremo ad eseguire un'analisi del tempo end to end (E2E) di una prenotazione da parte dell'utente, cioè dell'intervallo di tempo che trascorre dell'inizio della chiamata della funzionalità fino al suo termine.

Nei casi in cui si voglia garantire un tempo di risposta medio di una funzionalità, l'analisi E2E può essere fatta semplicemente osservando media e varianza dei tempi di esecuzione dei servizi che compongono tale funzionalità. Ci sono delle situazioni in cui però questo non è sufficiente e si vuole garantire un determinato Service Level Agreements (SLA), cioè si vuole lavorare con un upper-buond sul tempo di esecuzione. Il nostro obiettivo è quindi più stringente rispetto al tempo medio: ogni chiamata a una qualche funzionalità deve sempre ritornare entro un tempo all'interno di una soglia. Questo richiede non solo di avere dati statistici descrittivi, ma di essere in possesso dell'intera Probability Density Function (PDF) o della Cumulative Density Function (CDF) del workflow che ci interessa analizzare.

Un esempio di metrica che possiamo ottenere seguendo questo approccio e basandoci sulla PDF è la probabilità che il tempo di esecuzione sfori una data deadline $T_{max}$: semplicemente si ottienere integrando la PDF in $[T_{max},+\infty]$. Questo è un buon esempio di osservazione che non potremmo fare con le sole statistiche descrittive.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Eulero}
Per ottenere una distribuzione del tempo E2E di un workflow ci sono due tecniche: la prima è un'analisi numerica esatta, fattibile quando il workflow non è troppo complesso e i tempi di esecuzione seguono distribuzioni markoviane (i.e., esponenziali); la seconda è un'approssimazione basata su un approccio composizionale, che permette di analizzare anche workflow complessi con distribuzioni generali (\texttt{GEN}). Eulero utilizza questo secondo approccio bottom-up.

\subsection{Workflow complessi}
\label{subsec:complex_workflow}
Quando un workflow è complesso dobbiamo ricorrere a tecniche approssimate. La complessità di un workflow nella vita reale deriva dal fatto che i tempi di esecuzione dei microservizi non seguono distribuzioni esponenziali, cioè markoviane.

Quando i tempi di esecuzione sono esposizionali, l'unica cosa che condiziona il futuro del sistema è lo stato attuale. I possibili percorsi che il sistema può prendere da un certo punto in poi non considerano il passato e non considerano il tempo trascorso in quello stato. Quando però introduciamo distribuzioni non markoviene, il futuro viene condizionato anche dal passato. Questo provoca un'esplosioone dello spazio degli stati e rende l'analisi numerica esatta impossibile.

\subsection{Tool e analisi bottom-up}
Visto quanto detto sopra, per ottenere la PDF del tempo di esecuzione di un servizio abbiamo usato Eulero\cite{carnevali2023compositional}, un tool dell'STLAB dell'università di Firenze che esegue un'analisi bottom-up tramite un metodo composizionale: si divide il workflow in sub-workflow, fino ad unità elementari; si calcolano le PDF di queste unità; si compongono le varie PDF per ottenere la PDF del workflow completo.

Il vantaggio di questo approccio è la riduzione della complessità: si elimina infatti il condizionamento del futuro dagli stati precedenti anche per distribuzione \textit{GEN} e questo porta a una riduzione del numero deglis tati che devono essere analizzati. Il lato negativo è che si introduce un'errore di approssimazione nel tempo E2E calcolato.

\subsection{Dati necessari}
Senza scendere nel dettaglio, Eulero supporta workflow con strutture di controllo sequenziali (\texttt{SEQ}), parallele (\texttt{AND}), condizionali (\texttt{XOR}) e modellate con Direct Aciclyc Graph (\texttt{DAG}). Le strutture parallele e condizionali sono quelle descritte nella Sezione~\ref{sec:blocchi} e che sono stato poi implementate in car-rental.

Quello che dobbiamo fornire al tool per ottenere la distribuzione del tempo E2E è: la struttura del workflow modellata tramite blocchi, eventualmente annidati; la distribuzione marginale del tempo di esecuzione di ogni blocco elementare. Osserviamo che i blocchi e la loro composizione possono essere osservati dalla Figura~\ref{fig:new_workflow_jaeger} e dalla Figura~\ref{fig:new_workflow_sequence}; le distribuzioni sono invece ottenute nella Sezione~\ref{sec:distribuzioni}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Tracce}
\label{sec:traces}
Nella Sezione~\ref{cap:tracing} abbiamo descritto il funzionamento del collector di OpenTelemetry e come questo lavora all'interno della nostra applicazione. In questo momento ci interessa lavorare sulle tracce che il collector salva nel Persistant Volume Claim (PVC) \textit{otel-traces-pvc} e che sono accedebili dal pod \textit{analizer}; l'obiettivo è eseguire molti esperimenti, ottenere i tempi di esecuzione delle chiamate ai microservizi che poi possiamo usare per estrarre i dati necessari per Eulero.

\subsection{Generazione}
Per il nostro obiettivo ci servono molti dati e quindi moltre tracce da analizzare. Siccome generare queste tracce a mano non è molto pratico, è stato usato K6 come generatore di carico.

Il generatore di carico K6 può essere installato localmente su una macchina Linux, MacOS o Windows, ma ha anche il grande vantaggio di poter essere eseguito all'interno di un'infrestruttura cloud. Nel nostro progetto è utile e sensato distribuire K6 all'interno del cluster Minikube dove è in esecuzione la nostra applicazione; in questo modo può chiamare ogni risorsa di ogni servizio senza esporre tale servizio all'esterno del cluster. Per distribuire K6 in un cluster Kubernetes ci diversi modi, ma nel nostro caso è stato usato, come in gran parte del progetto, Helm. Su GitHub è possibile vedere l'installazione del \href{https://github.com/edoardosarri24/quarkus-car-rental/blob/21a410edfb1e2f9c0a3d74aa559f930ebc366494/services/external-services/k6}{job di K6}: helm utilizza la cartella \textit{templates/} per generare le risorse Kubernetes; il file \textit{templates/configmap.yaml} serve per iniettare lo script che il job dovrà eseguire; il file \textit{job.yaml} crea una Job Kubernetes che esegue tale script.

L'implementazione questo job è molto semplice: logicamente si tratta di un ciclo \texttt{for} che esegue per un certo intervallo di tempo specificato chiamando l'entry point del servizio di prenotazione. Prenota sempre la stessa macchina spostando l'intervallo della prenotazione in avanti di un giorno a ogni iterazione.

\subsection{Elaborazione}
Le tracce sono salvata in un singolo file \textit{traces.json}, che all'interno del pod \textit{analyzer} si trova nella directory \textit{data}. Si tratta di un JSON Lines, cioè un file dove ogni linea è un oggetto JSON indipendente.

L'elaborazione avviene portando i dati dal pod in memoria locale e poi eseguendo uno script costruito in modo da leggere ogni riga del file e analizzarla come json. L'output dell'analisi contiene delle statistiche descrittive (i.e., minimo, massimo, media, varianza e coefficiente di variazione) dei tempi di esecuzione di ogni microservizio. Queste statistiche saranno poi necessarie per ottenere le distribuzioni del tempo di esecuzione di ogni blocco del workflow.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Distribuzioni}
\label{sec:distribuzioni}
Per eseguire Eulero e ottenere la nostra PDF (o CDF) del tempo E2E del worflow ci servono le distribuzioni dei tempi di esecizione di ogni blocco di tale workflow. Al momento, come descritto nella Sezione~\ref{sec:traces}, abbiamo le statistiche descrittive dei tempi di esecuzione di ogni operazione che compone il workflow. Dobbiamo a questo punto utilizzare questi dati per ottenere delle distribuzioni che abbiano il miglior fitting sui nostri dati osservati tramite gli esperimenti.

\subsection{Approssimanti di Whitt}
Se abbiamo una distribuzione del tempo di esecuzione di un servizio, allora possiamo ottenere i dati semplicemente campionando da tale distribuzione. La nostra situazione è però l'opposta: abbiamo i tempi di esecuzione e ci serve una distribuzione che fitti bene i dati.

Una prima approssimazione può essere usando una distribuzione esponenziale, che inoltre, come abbiamo detto nella Sezione~\ref{subsec:complex_workflow}, ci semplificherebbe la vita da un punto di vista dell'analisi. Sappiamo che una distribuzione esponenziale ha un coefficiente di variazione (CV) pari a 1; questo però nella realtà non succede (praticamente) mai. I coefficienti di varaizione sono tutti $CV<1$ e questo implica che i nostri microservizi hanno una varianza maggiore di quella di una distribuzione esponenziale. In queste situazioni per trovare una distribuzione che approssimi bene i nostri dati si possono usare le approssimazioni di Whitt. I casi più comuni e che solitamente si usano sono:
\begin{itemize}
    \item HyperExp \\
        Si usa per dati che hanno un coefficiente di variazione $C_V>1$. Si tratta di uno XOR di due esponenziali, cioè di una distribuzione definita come $X=\begin{cases}Exp(\lambda_1) & \text{con prob } p \\Exp(\lambda_2) & \text{con prob } 1-p\end{cases}$; osserviamo che se $\lambda_1=\lambda_2$ allora abbiamo un'esponenziale.
    \item HypoExp \\
        Si usa per dati che hanno un coefficiente di variazione $C_V\in[\tfrac{1}{\sqrt{2}},1]$. Si tratta di una sequenza di esponenziali con tassi diversi, cioè di una distribuzione definita $X=Exp(\lambda_1)+\cdots+Exp(\lambda_n)$, con $\lambda_i\ne\lambda_j$.
    \item Erlang \\
        Si usa per dati che hanno un coefficiente di variazione $C_V=\tfrac{1}{\sqrt{k}}$, $\exists k$. Si tratta di una sequenza di $k$ esponenziali con tassi uguali, cioè di una distribuzione definita $X=k\cdot Exp(\lambda)$.
    \item GeneralizedErlang \\
        Si usa per dati che hanno un coefficiente di variazione $C_V<\tfrac{1}{\sqrt{2}}$. Si tratta di una sequenza di $k$ esponenziali con tasso $\lambda_1$ seguita da un'esponenziale con tasso $\lambda_2$, cioè di una distribuzione definita $X=k\cdot Exp(\lambda_1)+Exp(\lambda_2)$. Questo permtte di fittare dati che hanno un $CV\in(\tfrac{1}{\sqrt{k}},\tfrac{1}{\sqrt{k+1}})$.
\end{itemize}

\subsection{Risultati}
I risultati, cioè le distribuzioni che meglio fittano i dati ottenuti in precedenza, possono essere calcolate in funzione del valore atteso e del coefficiente di variazione. I risultati si trovano nel file \href{https://github.com/edoardosarri24/quarkus-car-rental/blob/fc1f21c74a9933e906df0e7e190190e35a22e5d6/E2E-analysis/extract_data/results/trace_analysis_stats.json}{trace\_analysis\_stats.json} presente su gitHub.

A questo punto abbiamo tutto per eseguire l'analisi finale e calcolare la distribuzione dei tempi E2E del nostro workflow.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Distribuzione E2E}
A questo abbiamo il workflow con i microservizi che vengono chiamati, mostrati in Figura~\ref{fig:new_workflow_sequence}, e le distribuzioni dei tempi di esecuzione di ogni microservizio: possiamo eseguire la simulazione su Eulero, che modella il nostro workflow con qualcosa di simile a quello che possiamo osservare in Figura~\ref{fig:STPN_workflow}.
\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{images/6-analisi/STPN_workflow.pdf}
    \caption{STPN del workflow~\cite{oris21}.}
    \label{fig:STPN_workflow}
\end{figure}

In Figura~\ref{fig:compare_e2e_distribution_correlation0} possiamo osservare il risultato ottenuto.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{images/6-analisi/compare_e2e_distribution_correlation0.pdf}
    \caption{Eulero and real distribution.}
    \label{fig:compare_e2e_distribution_correlation0}
\end{figure}