\chapter{Analisi E2E}
In questo capitolo andremo ad eseguire un'analisi del tempo end to end (E2E) di una prenotazione da parte dell'utente, cioè dell'intervallo di tempo che trascorre dell'inizio della chiamata della funzionalità fino al suo termine.

Nei casi in cui si voglia garantire un tempo di risposta medio di una funzionalità, l'analisi E2E può essere fatta semplicemente osservando media e varianza dei tempi di esecuzione dei servizi che compongono tale funzionalità. Ci sono delle situazioni in cui però questo non è sufficiente e si vuole garantire un determinato Service Level Agreements (SLA), cioè si vuole lavorare con un upper-buond sul tempo di esecuzione. Il nostro obiettivo è quindi più stringente rispetto al tempo medio: ogni chiamata a una qualche funzionalità deve sempre ritornare entro un tempo all'interno di una soglia. Questo richiede non solo di avere dati statistici descrittivi, ma di essere in possesso dell'intera Probability Density Function (PDF) o della Cumulative Density Function (CDF) del workflow che ci interessa analizzare.

Un esempio di metrica che possiamo ottenere seguendo questo approccio e basandoci sulla PDF è la probabilità che il tempo di esecuzione sfori una data deadline $T_{max}$: semplicemente si ottienere integrando la PDF in $[T_{max},+\infty]$. Questo è un buon esempio di osservazione che non potremmo fare con le sole statistiche descrittive.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Eulero}
Per ottenere una distribuzione del tempo E2E di un workflow ci sono due tecniche: la prima è un'analisi numerica esatta, fattibile quando il workflow non è troppo complesso e i tempi di esecuzione seguono distribuzioni markoviane (i.e., esponenziali); la seconda è un'approssimazione basata su un approccio composizionale, che permette di analizzare anche workflow complessi con distribuzioni generali (\texttt{GEN}). Eulero utilizza questo secondo approccio bottom-up.

\subsection{Workflow complessi}
\label{subsec:complex_workflow}
Quando un workflow è complesso dobbiamo ricorrere a tecniche approssimate. La complessità di un workflow nella vita reale deriva dal fatto che i tempi di esecuzione dei microservizi non seguono distribuzioni esponenziali, cioè markoviane.

Quando i tempi di esecuzione sono esposizionali, l'unica cosa che condiziona il futuro del sistema è lo stato attuale. I possibili percorsi che il sistema può prendere da un certo punto in poi non considerano il passato e non considerano il tempo trascorso in quello stato. Quando però introduciamo distribuzioni non markoviene, il futuro viene condizionato anche dal passato. Questo provoca un'esplosioone dello spazio degli stati e rende l'analisi numerica esatta impossibile.

\subsection{Tool e analisi bottom-up}
Visto quanto detto sopra, per ottenere la PDF del tempo di esecuzione di un servizio abbiamo usato Eulero\cite{carnevali2023compositional}, un tool dell'STLAB dell'università di Firenze che esegue un'analisi bottom-up tramite un metodo composizionale: si divide il workflow in sub-workflow, fino ad unità elementari; si calcolano le PDF di queste unità; si compongono le varie PDF per ottenere la PDF del workflow completo.

Il vantaggio di questo approccio è la riduzione della complessità: si elimina infatti il condizionamento del futuro dagli stati precedenti anche per distribuzione \textit{GEN} e questo porta a una riduzione del numero deglis tati che devono essere analizzati. Il lato negativo è che si introduce un'errore di approssimazione nel tempo E2E calcolato.

\subsection{Dati necessari}
Senza scendere nel dettaglio, Eulero supporta workflow con strutture di controllo sequenziali (\texttt{SEQ}), parallele (\texttt{AND}), condizionali (\texttt{XOR}) e modellate con Direct Aciclyc Graph (\texttt{DAG}). Le strutture parallele e condizionali sono quelle descritte nella Sezione~\ref{sec:blocchi} e che sono stato poi implementate in car-rental.

Quello che dobbiamo fornire al tool per ottenere la distribuzione del tempo E2E è: la struttura del workflow modellata tramite blocchi, eventualmente annidati; la distribuzione marginale del tempo di esecuzione di ogni blocco elementare. Osserviamo che i blocchi e la loro composizione possono essere osservati dalla Figura~\ref{fig:new_workflow_jaeger} e dalla Figura~\ref{fig:new_workflow_sequence}; le distribuzioni sono invece ottenute nella Sezione~\ref{sec:distribuzioni}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Tracce}
\label{sec:traces}
Nella Sezione~\ref{cap:tracing} abbiamo descritto il funzionamento del collector di OpenTelemetry e come questo lavora all'interno della nostra applicazione. In questo momento ci interessa lavorare sulle tracce che il collector salva nel Persistant Volume Claim (PVC) \textit{otel-traces-pvc} e che sono accedebili dal pod \textit{analizer}; l'obiettivo è eseguire molti esperimenti, ottenere i tempi di esecuzione delle chiamate ai microservizi che poi possiamo usare per estrarre i dati necessari per Eulero.

\subsection{Generazione}
Per il nostro obiettivo ci servono molti dati e quindi moltre tracce da analizzare. Siccome generare queste tracce a mano non è molto pratico, è stato usato K6 come generatore di carico.

Il generatore di carico K6 può essere installato localmente su una macchina Linux, MacOS o Windows, ma ha anche il grande vantaggio di poter essere eseguito all'interno di un'infrestruttura cloud. Nel nostro progetto è utile e sensato distribuire K6 all'interno del cluster Minikube dove è in esecuzione la nostra applicazione; in questo modo può chiamare ogni risorsa di ogni servizio senza esporre tale servizio all'esterno del cluster. Per distribuire K6 in un cluster Kubernetes ci diversi modi, ma nel nostro caso è stato usato, come in gran parte del progetto, Helm. Su GitHub è possibile vedere l'installazione del \href{https://github.com/edoardosarri24/quarkus-car-rental/blob/21a410edfb1e2f9c0a3d74aa559f930ebc366494/services/external-services/k6}{job di K6}: helm utilizza la cartella \textit{templates/} per generare le risorse Kubernetes; il file \textit{templates/configmap.yaml} serve per iniettare lo script che il job dovrà eseguire; il file \textit{job.yaml} crea una Job Kubernetes che esegue tale script.

L'implementazione questo job è molto semplice: logicamente si tratta di un ciclo \texttt{for} che esegue per un certo intervallo di tempo specificato chiamando l'entry point del servizio di prenotazione. Prenota sempre la stessa macchina spostando l'intervallo della prenotazione in avanti di un giorno a ogni iterazione.

\subsection{Elaborazione}
Le tracce sono salvata in un singolo file \textit{traces.json}, che all'interno del pod \textit{analyzer} si trova nella directory \textit{data}. Si tratta di un JSON Lines, cioè un file dove ogni linea è un oggetto JSON indipendente. L'elaborazione avviene portando i dati dal pod in memoria locale e poi eseguendo uno script costruito in modo da leggere ogni riga del file e analizzarla come json. L'output dell'analisi contiene delle statistiche descrittive (i.e., minimo, massimo, media, varianza e coefficiente di variazione) dei tempi di esecuzione di ogni microservizio. Queste statistiche saranno poi necessarie per ottenere le distribuzioni del tempo di esecuzione di ogni blocco del workflow.

Grazie a una caratteristica di OpenTelemetry è possibile anche ottenere la latenza di rete tra le varie chiaate. Per ogni microservizio viene raccolto sia il tempo \textit{server} che \textit{client}: il primo misura il tempo in cui il servizio è in esecuzione; il secondo misura il tempo che ci mette una chiamata a un altro servizio a tornare. Combinando insieme queste due informazioni, per due servezi consecutivi, si può ottenere il tempo in cui l'informazione è stata trasmessa.

\subsection{Risultati}
Possiamo osservare tutti le informazioni raccolte in \href{https://github.com/edoardosarri24/quarkus-car-rental/blob/4242d55e535adac82a10fb97dafd20de23b038b0/E2E-analysis/extract_data/results}{extract\_data/result}. Come si nota sono disponibili, per ogni microservizio, i tempi di server (i.e., per quanto il servizio esegue), i tempi di ogni chiamata e la latenza di rete.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Distribuzioni}
\label{sec:distribuzioni}
Per eseguire Eulero e ottenere la nostra PDF (o CDF) del tempo E2E del worflow ci servono le distribuzioni dei tempi di esecizione di ogni blocco di tale workflow. Al momento, come descritto nella Sezione~\ref{sec:traces}, abbiamo le statistiche descrittive dei tempi di esecuzione di ogni operazione che compone il workflow. Dobbiamo a questo punto utilizzare questi dati per ottenere delle distribuzioni che abbiano il miglior fitting sui nostri dati osservati tramite gli esperimenti.

\subsection{Approssimanti di Whitt}
Se abbiamo una distribuzione del tempo di esecuzione di un servizio, allora possiamo ottenere i dati semplicemente campionando da tale distribuzione. La nostra situazione è però l'opposta: abbiamo i tempi di esecuzione e ci serve una distribuzione che fitti bene i dati.

Una prima approssimazione può essere usando una distribuzione esponenziale, che inoltre, come abbiamo detto nella Sezione~\ref{subsec:complex_workflow}, ci semplificherebbe la vita da un punto di vista dell'analisi. Sappiamo che una distribuzione esponenziale ha un coefficiente di variazione (CV) pari a 1; questo però nella realtà non succede (praticamente) mai. I coefficienti di varaizione sono tutti $CV<1$ e questo implica che i nostri microservizi hanno una varianza maggiore di quella di una distribuzione esponenziale. In queste situazioni per trovare una distribuzione che approssimi bene i nostri dati si possono usare le approssimazioni di Whitt. I casi più comuni e che solitamente si usano sono:
\begin{itemize}
    \item HyperExp \\
        Si usa per dati che hanno un coefficiente di variazione $C_V>1$. Si tratta di uno XOR di due esponenziali, cioè di una distribuzione definita come $X=\begin{cases}Exp(\lambda_1) & \text{con prob } p \\Exp(\lambda_2) & \text{con prob } 1-p\end{cases}$; osserviamo che se $\lambda_1=\lambda_2$ allora abbiamo un'esponenziale.
    \item HypoExp \\
        Si usa per dati che hanno un coefficiente di variazione $C_V\in[\tfrac{1}{\sqrt{2}},1]$. Si tratta di una sequenza di esponenziali con tassi diversi, cioè di una distribuzione definita $X=Exp(\lambda_1)+\cdots+Exp(\lambda_n)$, con $\lambda_i\ne\lambda_j$.
    \item Erlang \\
        Si usa per dati che hanno un coefficiente di variazione $C_V=\tfrac{1}{\sqrt{k}}$, $\exists k$. Si tratta di una sequenza di $k$ esponenziali con tassi uguali, cioè di una distribuzione definita $X=k\cdot Exp(\lambda)$.
    \item GeneralizedErlang \\
        Si usa per dati che hanno un coefficiente di variazione $C_V<\tfrac{1}{\sqrt{2}}$~\cite{8681237}. Si tratta di una sequenza di $k$ esponenziali con tasso $\lambda_1$ seguita da un'esponenziale con tasso $\lambda_2$, cioè di una distribuzione definita $X=k\cdot Exp(\lambda_1)+Exp(\lambda_2)$. Questo permtte di fittare dati che hanno un $CV\in(\tfrac{1}{\sqrt{k+1}},\tfrac{1}{\sqrt{k}})$.
\end{itemize}

\subsection{Risultati}
I risultati, cioè le distribuzioni che meglio fittano i dati ottenuti in precedenza, possono essere calcolate in funzione del valore atteso e del coefficiente di variazione. I risultati si trovano nel file \href{https://github.com/edoardosarri24/quarkus-car-rental/blob/fc1f21c74a9933e906df0e7e190190e35a22e5d6/E2E-analysis/extract_data/results/trace_analysis_stats.json}{trace\_analysis\_stats.json} presente su gitHub.

A questo punto abbiamo tutto per eseguire l'analisi finale e calcolare la distribuzione dei tempi E2E del nostro workflow.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Distribuzione E2E}
A questo abbiamo il workflow con i microservizi che vengono chiamati, mostrati in Figura~\ref{fig:new_workflow_sequence}, e le distribuzioni dei tempi di esecuzione di ogni microservizio: possiamo eseguire la simulazione su Eulero, che modella il nostro workflow con qualcosa di simile a quello che possiamo osservare in Figura~\ref{fig:STPN_workflow}.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{images/6-analisi/STPN_workflow.pdf}
    \caption{STPN del workflow~\cite{oris21}.}
    \label{fig:STPN_workflow}
\end{figure}

In Figura~\ref{fig:compare_e2e_distribution_correlation0} possiamo osservare il risultato ottenuto. È interessante mostrare anche, in Figura~\ref{fig:latency_network_statistics} le statistiche (i.e., media e varianza) della latenza di rete che c'è nelle varie chiamate.
\begin{figure}[htbp]
    \centering
    \begin{subfigure}{0.75\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/6-analisi/compare_e2e_distribution_correlation0.pdf}
        \caption{Eulero and real distribution.}
        \label{fig:compare_e2e_distribution_correlation0}
    \end{subfigure}
    \hfill
    \centering
    \begin{subfigure}{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/6-analisi/latency_network.pdf}
        \caption{Latenza di rete.}
        \label{fig:latency_network_statistics}
    \end{subfigure}
    \caption{Risultati dell'esperimento.}
\end{figure}

Per valutare la differenza delle due CDF ottenute sono state usate due misure:
\begin{itemize}
    \item Dominance: Si tratta di una misura che quantifica la probabilità che una random variable $X$ sia minore di una random variable $Y$, cioè $\delta(X,Y)=P\{X\le Y\}$: se $\delta(X,Y)\ge\tfrac{1}{2}$ allora $X$ arriva dopo $Y$~\cite{11068943}.
    \item Difference area: Per ogni punto si calcola il valore assoluto della differenza tra la vera CDF e quella ottenuta da Eulero. Il valore è dato dalla somma di queste differenze. È stato calcolato sia l'errore L1 (assoluto) che quadratico.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Bande di confidenza}
\label{sec:confidence_bands}
Quando eseguiamo degli esperimenti lavoriamo con i dati provenienti dalle nostre simulazioni, ma non con la loro vera distribuzione: possiamo definire la distribuzione solo in modo campionario e non assoluto. Per trattare in modo statistico i dati e trarre precise conferme (e.g., in casi di performance analysis) ci serve capire quanto le distribuzioni campionarie sono precise e quanto possiamo fare affidamento su di esse. Un modo per fare questo è usare le bande di confidenza. Possiamo in questo modo verificare, con una fissata confidenza di $1-\alpha$, quanto è accurata la distribuzione ottenuta e se è necessario aumentare i campioni dell'esperimento perché vogliamo una maggiore accuratezza.

Per ricavare queste bande di confidenza ci sono solitamente due approccu:
\begin{itemize}
    \item Pointwise band \\
        Le bande di confidenza sono definite analizzando ogni punto della CDF in modo isolato. Sono tecniche valide quando ci interessa capire l'affidabilità di valore specifico (e.g., quale è la probabilità che il mio esperimento restituisca un valore minore di $x$), oppure quando si vuole analizzare i percentili. In questi contesti sono meno conservative e quindi più precise.
    \item Simultaneus band \\
        Fornisco delle bande probabilistiche di confidenza della CDF della distribuzione da cui derivano i dati e garantiscono che la vera curva della CDF resti all'interno delle bande con confidenza $1-\alpha$. Permettono quindi di ottenere delle garanzie sull'intera popolazione senza sapere nulla della vera distribuzione.
\end{itemize}

\subsection{Tecniche}
Le tecniche più comuni sono:
\begin{itemize}
    \item Approssimazione normale \\
        Si tratta della tecnica base più citata in letteratura~\cite{wiki:binomial_proportion}. Utilizza la distribuzione binomiale per determinare gli intervallie di confidenza di un punto della CDF. Il metodo approssima la distribuzione a una gaussiana; per una binomiale questo vuol dire supporre che il numero di esperimenti tenda a infinito o che la probabilità sia $p=0.5$. Questo fa si che questa tecnica sia buona quando il numero di dati è molto elevato.

        I problemi principali che si possono incontrare sono:
        \begin{itemize}
            \item Copertura a salti \\
                Se chiediamo un grado di confidenza di $1-\alpha\%$ può succedere che per alcuni punti questo sia rispettato, per altri più alto e per altri ancora più basso.
            \item Asimmetria \\
                Per eventi che hanno una probabilità molto bassa o molto alta la distribuzione diventa molto asimmetrica, ma i metodi standard si assumono che essa sia una campana simmetrica.
            \item Numero di successi limite \\
                Se osserviamo valore di $k=0$ o $K=N$ allora otteniamo i metodi standard portano a divisioni per zero e altri problemi.
        \end{itemize}
    \item Clopper-Pearson \\
        Si basa sulla distribuzione binomiale e risolve i problemi base che si hanno con l'approssimazione normale o tecniche simili~\cite{glen:clopper_pearson}. L'idea è cercare tutti i valori di $p$ per cui le formule sotto funzionano. Questo porta a: avere costo computazionale alto, per cui si usa la relazione tra distribuzione binomiale e distribuzione beta; essere conservativo; garantire una copertura completa. Gli intervalli sono definiti da due valori:
        \begin{itemize}
            \item $p_{inf}$ \\
                È il valore di $p$ della binomiale per cui la probabilità di osservare almeno $k$ successi è esattamente $\alpha/2$, cioè $\displaystyle\sum_{i=k}^n\binom{n}{i}p_{inf}^i(1-p_{inf})^{n-i}=\tfrac{\alpha}{2}$. Usando la distribuzione beta si ha poi $B(\alpha/2, X, n-X+1)$.
            \item $p_{sup}$ \\
                È il valore di $p$ della binomiale per cui la probabilità di osservare al più $k$ successi è esattamente $\alpha/2$, cioè $\displaystyle\sum_{i=0}^k\binom{n}{i}p_{inf}^i(1-p_{sup})^{n-i}=\tfrac{\alpha}{2}$. Usando la distribuzione beta si ha poi $B(1-\alpha/2, X+1, n-X)$.
        \end{itemize}
    \item Dvoretzky-Kiefer-Wolfowitz (DKW) \\
        È una tecnica che definsice delle bande parallele alla CDF campionaria di ampiezza costante $\epsilon=\sqrt{\tfrac{ln(2/\alpha)}{2n}}$~\cite{wiki:dkw_inequality}. Siccome l'ampiezza è fissa in ogni punto della CDF, tende a essere troppo conservativa e quindi è una buona tecnica quando si lavora in contesti di sicurezza. La matematica ci dice che la vera CDF $F(x)$ è in $L(x)\le F(x)\le U(x)$, dove $U(x)=\min(F_n(x)+\epsilon,1)$ e $L(x)=\min(F_n(x)-\epsilon,0)$, con $F_n(x)$ che è la CDF campionaria.
    \item Non-parametric Bootstrap \\
        Si tratta di un approccio data-driven~\cite{breheny2016bootstrap}: invece che usare formule teoriche che solitamente fanno assunzioni come il tipo di distribuzione o il numero di campioni infiniti, in questo caso si usano i dati per studiare la variabilità dei dati. L'idea è quella di campionare $n$ elementi dalla distribuzione campionaria $F$ in modo da definire una CDF empirica $F^*$; se ripetiamo questo processo per $N$ volte, per ogni valore $x$ all'interno del range che i nostri dati assumono avremo molti valori di $F^*(x)$. A questo punto possiamo definire le bande di confidenza in due modi; in entrambi i casi la  in entrambi i casi le bande ottenuto sono meno conservative di quelle derivate dai metodi Pearson-Clopper e DKW.
        \begin{itemize}
            \item Pointwise \\
                Se abbiamo intervallo di confidenza del 95\% allora prendiamo il 2.5° percentile e il 97.5° percentile dei valori assunti da tutte le $F^*(x)$ ottenute. Avremo in questo modo una banda di confidenza che varia in funzione di $x$.
            \item Simultaneus \\
                Si condiera il valore massimo di $|F(x)-F^*(x)|$ per ogni $x$. Si prendono poi i percentili di questi valori massimi.  Avremo in questo modo una banda di confidenza di ampiezza costante.
        \end{itemize}
    \end{itemize}

\subsection{Risultati}
I risultati ottenuti, che possiamo notare in Figura~\ref{fig:distribution_with_bands_many_traces}, richiedono una confidenza del 99\%.

Possiamo notare come il nostro numero di campioni è stato abbastanza elevato da produrre una CDF campionaria abbastanza precisa. Inoltre, esattamente come ci dice la teoria, le bande di tipo simultaneus hanno la stessa distanza media che massima dalla CDF campionaria: questo dimostra che esse sono a una distanza fissa dalla CDF campionaria. Le bande di tipo pointwise invece hanno una distanza variabile.

Un'altra osservazione che possiamo portare riguarda la similarità delle bande ottenuto con i metodi Clopper-Pearson, DKW e bootstrapping: se guardiamo all'ampiezza e consideriamo lo stesso tipo di banda (i.e., pointwise vs simultaneus), notiamo come metodi diversi producono bande molto simili.

\begin{figure}[htbp]
    \centering
    \begin{minipage}{0.45\textwidth}
        \centering
        \begin{subfigure}{\textwidth}
            \centering
            \includegraphics[width=\textwidth]{images/6-analisi/with_confidence_bands/compare_e2e_distribution_cp.pdf}
            \caption{Pointwise con Clopper-Pearson.}
            \label{fig:correlation0_clopper_perason}
        \end{subfigure}
        \vfill
        \begin{subfigure}{\textwidth}
            \centering
            \includegraphics[width=\textwidth]{images/6-analisi/with_confidence_bands/compare_e2e_distribution_dkw.pdf}
            \caption{Simultaneus con DKW}
            \label{fig:correlation0_dkw}
        \end{subfigure}
    \end{minipage}
    \hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \begin{subfigure}{\textwidth}
            \centering
            \includegraphics[width=\textwidth]{images/6-analisi/with_confidence_bands/compare_e2e_distribution_bootstrap_pointwise.pdf}
            \caption{Pointwise con bootstrapping.}
            \label{fig:correlation0_bootstrap_pointwise}
        \end{subfigure}
        \vfill
        \begin{subfigure}{\textwidth}
            \centering
            \includegraphics[width=\textwidth]{images/6-analisi/with_confidence_bands/compare_e2e_distribution_bootstrap_simultaneous.pdf}
            \caption{Simultaneus con bootstrapping.}
            \label{fig:correlation0_bootstrap_simultaneous}
        \end{subfigure}
    \end{minipage}
    \caption{Bande di confidenza per l'esperimento con molte tracce.}
    \label{fig:distribution_with_bands_many_traces}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Pochi dati}
Vediamo adesso cosa succede ai nostri esperimento quando abbiamo pochi dati. Rispetto al caso analizzato fino a ora, dove il numerod i tracce era di 5893, in questa situazione abbiamo campionato in modo randomico l'8\% delle tracce, cioè abbiamo usato 456 tracce.

I risultati ottenuti, come si può notare in Figura~\ref{fig:distribution_with_bands_few_traces}. sono decisamente peggiori sotto ogni aspetto. Specifichiamo che le bande sono ottenute sempre con una confidenza del 99\%, esattamente come in precedenza.
\begin{itemize}
    \item La CDF campionaria si trova molto alla destra di quella ottenuta con Eulero.
    \item Le bande di confidenza, se paragonate due a due con quelle ottenuto con molte tracce, sono decisamente pià large. Questo sta a significare che avere più campioni permette di ottenere una distribuzione campionaria più affidabile.
\end{itemize}

\begin{figure}[htbp]
    \centering
    \begin{minipage}{0.45\textwidth}
        \centering
        \begin{subfigure}{\textwidth}
            \centering
            \includegraphics[width=\textwidth]{images/6-analisi/with_confidence_bands/correlation0_8_of_traces/compare_e2e_distribution_cp.pdf}
            \caption{Pointwise con Clopper-Pearson.}
        \end{subfigure}
        \vfill
        \begin{subfigure}{\textwidth}
            \centering
            \includegraphics[width=\textwidth]{images/6-analisi/with_confidence_bands/correlation0_8_of_traces/compare_e2e_distribution_dkw.pdf}
            \caption{Simultaneus con DKW}
        \end{subfigure}
    \end{minipage}
    \hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \begin{subfigure}{\textwidth}
            \centering
            \includegraphics[width=\textwidth]{images/6-analisi/with_confidence_bands/correlation0_8_of_traces/compare_e2e_distribution_bootstrap_pointwise.pdf}
            \caption{Pointwise con bootstrapping.}
        \end{subfigure}
        \vfill
        \begin{subfigure}{\textwidth}
            \centering
            \includegraphics[width=\textwidth]{images/6-analisi/with_confidence_bands/correlation0_8_of_traces/compare_e2e_distribution_bootstrap_simultaneous.pdf}
            \caption{Simultaneus con bootstrapping.}
        \end{subfigure}
    \end{minipage}
    \caption{Bande di confidenza con poche (456) tracce.}
    \label{fig:distribution_with_bands_few_traces}
\end{figure}