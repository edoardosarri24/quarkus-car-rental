\chapter{Analisi E2E}
In questo capitolo andremo ad eseguire un'analisi del tempo end to end (E2E) di una prenotazione da parte dell'utente, cioè dell'intervallo di tempo che trascorre dell'inizio della chiamata della funzionalità fino al suo termine, usando un approccio data-driven: supporemo di non avere il modello del sistema e usaremo i dati raccolti tramite il tracing per arrivare a delle conclusioni. Questo approccio è molto utile in quelle situazioni in cui il nostro workflow è composto da moltissimi microservizi senza un'idea precisa dei tempi di esecuzione e delle relazioni tra di essi.

Nei casi in cui si voglia garantire un tempo di risposta medio di una funzionalità, l'analisi E2E può essere fatta semplicemente osservando media e varianza dei tempi di esecuzione dei servizi che compongono tale funzionalità. Ci sono delle situazioni in cui però questo non è sufficiente e si vuole garantire un determinato Service Level Agreements (SLA), cioè si vuole lavorare con un upper-buond sul tempo di esecuzione. Il nostro obiettivo è quindi più stringente rispetto al tempo medio: ogni chiamata a una qualche funzionalità deve sempre ritornare entro un tempo all'interno di una soglia. Questo richiede non solo di avere dati statistici descrittivi, ma di essere in possesso dell'intera Probability Density Function (PDF) del workflow che ci interessa analizzare.

Un esempio di metrica che possiamo ottenere seguendo questo approccio e basandoci sulla PDF è la probabilità che il tempo di esecuzione sfori una data deadline $T_{max}$: semplicemente si ottienere integrando la PDF in $[T_{max},+\infty]$. Questo è un buon esempio di osservazione che non potremmo fare senza conoscere la PDF.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Eulero (l'intro è giusta?)}
Per analizzare i workflow ci sono sostanzialmente due tecniche: la prima è un'analisi numerica ed esatta, che è fattibile quando il workflow non è troppo complesso e i tempi di esecuzione seguono distribuzioni semplici e markoviane (i.e., esponenziali); la seconda è una'analisi approssimata che permette di analizzare anche workflow più complessi con distribuzioni generali (\texttt{GEN}).

\subsection{Workflow complessi}
Quando un workflow è complesso dobbiamo ricorrere a tecniche approssimate. Se modelliamo un workflow tramite un Direct Aciclyc Graph (e.g., STPN), allora l'analisi può essere fatta tramite la transient analysis. \textbf{manca roba?}

Quando i tempi di esecuzione sono esposizionali, l'unica cosa che condiziona il futuro del sistema è lo stato attuale. Nella realtà però il mondo non è esponenziale e quindi le random variable che descrivono i tempi di esecuzione sono non markoviane. Questo porta a condizionare il futuro del sistema non solo dallo stato attuale ma anche dal tempo trascorso in tale stato: si ha un'esplosione del numero degli stati da analizzare.

\subsection{Tool e analisi bottom-up}
Visto quanto detto sopra, per ottenere la PDF del tempo di esecuzione di un servizio abbiamo usato Eulero\cite{carnevali2023compositional}, un tool dell'STLAB dell'università di Firenze che esegue un'analisi bottom-up tramite un metodo composizionale: si divide il workflow in sub-workflow, fino ad unità elementari; si calcolano le PDF di queste unità; si compongono le varie PDF per ottenere la PDF del workflow completo.

Il vantaggio di questo approccio è la riduzione della complessità: \textbf{si elimina infatti il condizionamento dello stato attuale dagli stati precedenti; questo porta a ridurre lo spazio degli stati quando si utilizza la transient analysis durante l'analisi}. \textbf{Il lato negativo è che si introduce un'errore di approssimazione nel tempo E2E calcolato: non riusciamo a modellare e a cogliere la relazione tra i tempi di esecuzione di due stati vicini}.

Senza scendere nel dettaglio, Eulero supporta workflow con strutture di controllo sequenziali (\texttt{SEQ}), parallele (\texttt{AND}), condizionali (\texttt{XOR}) e modellate con Direct Aciclyc Graph (\texttt{DAG}). Le strutture parallele e condizionali sono quelle descritte nella Sezione~\ref{sec:blocchi} e che sono stato poi implementate in car-rental.

\subsection{Blocchi}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Analisi traces}
Nella Sezione~\ref{cap:tracing} abbiamo descritto il funzionamento del collector di OpenTelemetry e come questo lavora all'interno della nostra applicazione. In questo momento ci interessa lavorare sulle tracce che il collector salva nel Persistant Volume Claim (PVC) \textit{otel-traces-pvc} e che sono accedebili dal pod \textit{analizer}; l'obiettivo è estrarre dei dati che siano poi analizzabili da Eulero.

\subsection{Formato tracce}
Le tracce sono salvata in un singolo file \textit{traces.json}, che all'interno del pod \textit{analyzer} si trova nella directory \textit{data}. Si tratta di un JSON Lines, cioè un file dove ogni linea è un oggetto JSON indipendente. Lo \href{https://github.com/edoardosarri24/quarkus-car-rental/blob/master/E2E-analysis/extract_traces}{script} è costruito in modo da leggere ogni riga del file e analizzarla come json.

\subsection{Risultato}
Quello che viene prodotto è...