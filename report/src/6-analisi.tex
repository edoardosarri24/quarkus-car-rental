\chapter{Analisi E2E}
In questo capitolo andremo ad eseguire un'analisi del tempo end to end (E2E) di una prenotazione da parte dell'utente, cioè dell'intervallo di tempo che trascorre dell'inizio della chiamata della funzionalità fino al suo termine, usando un approccio data-driven: supporremo di non avere il modello del workflow e usaremo i dati raccolti tramite il tracing per arrivare a delle conclusioni. Questo approccio è molto utile in quelle situazioni in cui il nostro workflow è composto da moltissimi microservizi, ma non abbiamo un'idea precisa dei tempi di esecuzione e delle relazioni tra di essi.

Nei casi in cui si voglia garantire un tempo di risposta medio di una funzionalità, l'analisi E2E può essere fatta semplicemente osservando media e varianza dei tempi di esecuzione dei servizi che compongono tale funzionalità. Ci sono delle situazioni in cui però questo non è sufficiente e si vuole garantire un determinato Service Level Agreements (SLA), cioè si vuole lavorare con un upper-buond sul tempo di esecuzione. Il nostro obiettivo è quindi più stringente rispetto al tempo medio: ogni chiamata a una qualche funzionalità deve sempre ritornare entro un tempo all'interno di una soglia. Questo richiede non solo di avere dati statistici descrittivi, ma di essere in possesso dell'intera Probability Density Function (PDF) o della Cumulative Density Function (CDF) del workflow che ci interessa analizzare.

Un esempio di metrica che possiamo ottenere seguendo questo approccio e basandoci sulla PDF è la probabilità che il tempo di esecuzione sfori una data deadline $T_{max}$: semplicemente si ottienere integrando la PDF in $[T_{max},+\infty]$. Questo è un buon esempio di osservazione che non potremmo fare con le sole statistiche descrittive.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Eulero}
I workflow possono essere modellati tramite modelli formali come le Stocastic Time Petri Nets (STPN). Per ottenere una distribuzione del tempo E2E di un workflow ci sono due tecniche: la prima è un'analisi numerica esatta, fattibile quando il workflow non è troppo complesso e i tempi di esecuzione seguono distribuzioni markoviane (i.e., esponenziali); la seconda è un'approssimazione basata su un approccio composizionale, che permette di analizzare anche workflow complessi con distribuzioni generali (\texttt{GEN}).

\subsection{Workflow complessi}
Quando un workflow è complesso dobbiamo ricorrere a tecniche approssimate. La complessità di un workflow nella vita reale deriva dal fatto che i tempi di esecuzione dei microservizi non seguono distribuzioni esponenziali, cioè markoviane.

Quando i tempi di esecuzione sono esposizionali, l'unica cosa che condiziona il futuro del sistema è lo stato attuale. I possibili percorsi che il sistema può prendere da un certo punto in poi non considerano il passato e non considerano il tempo trascorso in quello stato.

Quando però introduciamo distribuzioni non markoviene, il futuro viene condizionato anche dal passato. Questo provoca un'esplosioone dello spazio degli stati e rende l'analisi numerica esatta impossibile.

\subsection{Tool e analisi bottom-up}
Visto quanto detto sopra, per ottenere la PDF del tempo di esecuzione di un servizio abbiamo usato Eulero\cite{carnevali2023compositional}, un tool dell'STLAB dell'università di Firenze che esegue un'analisi bottom-up tramite un metodo composizionale: si divide il workflow in sub-workflow, fino ad unità elementari; si calcolano le PDF di queste unità; si compongono le varie PDF per ottenere la PDF del workflow completo.

Il vantaggio di questo approccio è la riduzione della complessità: si elimina infatti il condizionamento del futuro dagli stati precedenti anche per distribuzione \textit{GEN} e questo porta a una riduzione del numero deglis tati che devono essere analizzati. Il lato negativo è che si introduce un'errore di approssimazione nel tempo E2E calcolato.

Senza scendere nel dettaglio, Eulero supporta workflow con strutture di controllo sequenziali (\texttt{SEQ}), parallele (\texttt{AND}), condizionali (\texttt{XOR}) e modellate con Direct Aciclyc Graph (\texttt{DAG}). Le strutture parallele e condizionali sono quelle descritte nella Sezione~\ref{sec:blocchi} e che sono stato poi implementate in car-rental.

\subsection{Blocchi}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Analisi traces}
Nella Sezione~\ref{cap:tracing} abbiamo descritto il funzionamento del collector di OpenTelemetry e come questo lavora all'interno della nostra applicazione. In questo momento ci interessa lavorare sulle tracce che il collector salva nel Persistant Volume Claim (PVC) \textit{otel-traces-pvc} e che sono accedebili dal pod \textit{analizer}; l'obiettivo è estrarre dei dati che siano poi analizzabili da Eulero.

\subsection{Formato tracce}
Le tracce sono salvata in un singolo file \textit{traces.json}, che all'interno del pod \textit{analyzer} si trova nella directory \textit{data}. Si tratta di un JSON Lines, cioè un file dove ogni linea è un oggetto JSON indipendente. Lo \href{https://github.com/edoardosarri24/quarkus-car-rental/blob/master/E2E-analysis/extract_traces}{script} è costruito in modo da leggere ogni riga del file e analizzarla come json.

\subsection{Risultato}
Quello che viene prodotto è...